{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3fe00d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import math, os, re, time, random, string\n",
    "import numpy as np, pandas as pd, seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict\n",
    "import wordcloud\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a881fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_cleaned.csv')\n",
    "test = pd.read_csv('test_cleaned.csv')\n",
    "#train = pd.read_csv('train_cleaned_lite.csv')\n",
    "#test = pd.read_csv('test_cleaned_lite.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a0a6932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets shape (7613,)\n"
     ]
    }
   ],
   "source": [
    "train['text'] = train['text'].astype(str)\n",
    "test['text'] = test['text'].astype(str)\n",
    "\n",
    "labels = train['target']\n",
    "print('targets shape', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3f70c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6090, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1523, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6090,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1523,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, labels, test_size = 0.2, stratify=labels)\n",
    "X_train.shape\n",
    "X_val.shape\n",
    "y_train.shape\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06be345",
   "metadata": {},
   "source": [
    "#### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11036959",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [X_train, X_val, test]:\n",
    "    i['text'] = i['text'].astype(str)\n",
    "\n",
    "\n",
    "X_train_text = [i for i in X_train['text']]\n",
    "X_val_text = [i for i in X_val['text']]\n",
    "test_text = [i for i in test['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07967b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11060 unique tokens\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(X_train_text)\n",
    "\n",
    "print(len(tokenizer.word_index), 'unique tokens')\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train_text)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val_text)\n",
    "test_seq = tokenizer.texts_to_sequences(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "057be893",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data = pad_sequences(X_train_seq)\n",
    "X_val_data = pad_sequences(X_val_seq, X_train_data.shape[1])\n",
    "test_data = pad_sequences(test_seq, X_train_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afd67186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6090, 23)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1523, 23)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3263, 23)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_data.shape\n",
    "X_val_data.shape\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f5c19a",
   "metadata": {},
   "source": [
    "### Meta-feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "084326ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train.iloc[:, 2:])\n",
    "\n",
    "meta_train = scaler.transform(X_train.iloc[:, 2:])\n",
    "meta_val = scaler.transform(X_val.iloc[:, 2:])\n",
    "meta_test = scaler.transform(test.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93ce7605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6090, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1523, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3263, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train.shape\n",
    "meta_val.shape\n",
    "meta_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfdb07e",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36987f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_acc_plot(history):\n",
    "    scores = pd.DataFrame(history.history)\n",
    "    scores[['loss', 'val_loss']].plot();\n",
    "    scores[['accuracy', 'val_accuracy']].plot();\n",
    "    #scores[['f1_score', 'val_f1_score']].plot();\n",
    "\n",
    "answers = pd.read_csv('answer key.csv')\n",
    "y_true = answers['target']\n",
    "\n",
    "def kaggle(model, filename=''):\n",
    "    y_pred = (model.predict([test_data, meta_test]) > 0.5).astype(int)\n",
    "    print('\\nf1 score is:', f1_score(y_true, y_pred, average='macro'))\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    if filename != '':\n",
    "        submission=pd.read_csv('sample_submission.csv')\n",
    "        submission['target']=y_pred\n",
    "        submission.to_csv(filename+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a029a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', \n",
    "                              factor = 0.5, \n",
    "                              verbose = 1, \n",
    "                              patience = 4,                        \n",
    "                              min_lr = 0.0001)\n",
    "\n",
    "def model_process(model, n_epochs=20, model_name='', filename=''):\n",
    "    model.summary()\n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath = model_name+'.hdf5', \n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=True,\n",
    "                                   monitor='val_loss')\n",
    "\n",
    "    history = model.fit(x=[X_train_data, meta_train],\n",
    "                        y=y_train,\n",
    "                        epochs = n_epochs,\n",
    "                        verbose=1,\n",
    "                        callbacks=[checkpointer, reduce_lr],\n",
    "                        validation_data = ([X_val_data, meta_val], y_val)\n",
    "                       )\n",
    "    \n",
    "    loss_acc_plot(history)\n",
    "    \n",
    "    model.load_weights(model_name+'.hdf5')\n",
    "    \n",
    "    loss, acc = model.evaluate([X_val_data, meta_val], y_val)\n",
    "    print('\\nModel accuracy on validation set = ', acc)\n",
    "    print('\\nModel loss on validation set = ', loss)\n",
    "    \n",
    "    y_val_pred = (model.predict([X_val_data, meta_val]) > 0.5).astype(int)\n",
    "    print('\\nModel F1 on validation set = ', f1_score(y_val, y_val_pred, average='macro'))\n",
    "    \n",
    "    kaggle(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "112a2ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400001it [00:20, 19771.88it/s]\n",
      "100%|██████████| 11060/11060 [00:00<00:00, 460427.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our embedded matrix is of dimension (11061, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('glove.6B/glove.6B.200d.txt','r', encoding=\"utf8\") as f:\n",
    "    for line in tqdm(f):\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "EMBEDDING_DIM = 200  \n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "#initialize embedding matrix with zeros\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "\n",
    "#add glove word encodings to our library\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        \n",
    "        #words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "print(\"Our embedded matrix is of dimension\", embedding_matrix.shape)\n",
    "\n",
    "embedding = Embedding(len(word_index) + 1, EMBEDDING_DIM, weights = [embedding_matrix],\n",
    "                     input_length = 23, trainable = False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66001c38",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "453d93db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    LSTM_dropout = trial.suggest_discrete_uniform('LSTM_dropout', 0.0, 0.8, 0.1)\n",
    "    dropout = trial.suggest_discrete_uniform('dropout', 0.0, 0.8, 0.1)\n",
    "    spatial_dropout = trial.suggest_discrete_uniform('spatial_dropout', 0.0, 0.8, 0.1)\n",
    "    \n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = trial.suggest_categorical(\"optimizer\", [Adam, RMSprop])\n",
    "    \n",
    "    LSTM1 = trial.suggest_int('units1', 10, 100, step=10)\n",
    "    LSTM2 = trial.suggest_int('units2', 10, 100, step=10)\n",
    "    dense_units = trial.suggest_int('dense_units', 10, 100, step=10)\n",
    "    \n",
    "        \n",
    "    #model\n",
    "    nlp_input = Input(shape = (23,), name = 'nlp_input')\n",
    "    meta_input_train = Input(shape = (7, ), name = 'meta_train')\n",
    "    \n",
    "    emb = embedding(nlp_input)\n",
    "    emb = SpatialDropout1D(spatial_dropout)(emb)\n",
    "\n",
    "    nlp_out = Bidirectional(LSTM(LSTM1, dropout=LSTM_dropout, return_sequences=True))(emb)  \n",
    "    nlp_out = SpatialDropout1D(spatial_dropout)(nlp_out)\n",
    "    \n",
    "    nlp_out = Bidirectional(LSTM(LSTM2, dropout=LSTM_dropout))(emb)   \n",
    "     \n",
    "    #add meta data    \n",
    "    x = Concatenate()([nlp_out, meta_input_train])\n",
    "    \n",
    "    #add second hidden layer\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = (Dense(dense_units, \n",
    "               activation = 'relu'\n",
    "              ))(x)\n",
    "    \n",
    "    #add output layer\n",
    "    x = Dropout(dropout)(x)\n",
    "    preds = Dense(1, \n",
    "                  activation='sigmoid'\n",
    "                 )(x)\n",
    "    \n",
    "    #compile model\n",
    "    model = Model(inputs=[nlp_input , meta_input_train], outputs = preds)\n",
    "\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer(lr), metrics = ['accuracy'])\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', \n",
    "                              factor = 0.5, \n",
    "                              verbose = False, \n",
    "                              patience = 4,                        \n",
    "                              min_lr = 0.0001)\n",
    "    \n",
    "    pruning = optuna.integration.TFKerasPruningCallback(trial, 'val_accuracy')\n",
    "    \n",
    "    model.fit(x=[X_train_data, meta_train],\n",
    "                        y=y_train,\n",
    "                        epochs = 15,\n",
    "                        verbose=False,\n",
    "                        callbacks=[reduce_lr, pruning],\n",
    "                        validation_data = ([X_val_data, meta_val], y_val),\n",
    "                        shuffle=True\n",
    "                       )\n",
    "    y_pred = (model.predict([test_data, meta_test]) > 0.5).astype(int)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "84222668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-22 22:23:21,725]\u001b[0m A new study created in memory with name: no-name-77338653-bad4-4b57-a8f6-63a45eae2c99\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:23:41,527]\u001b[0m Trial 0 finished with value: 0.7162570973172621 and parameters: {'LSTM_dropout': 0.7000000000000001, 'dropout': 0.6000000000000001, 'spatial_dropout': 0.6000000000000001, 'lr': 0.018086759576374796, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop'>, 'units1': 60, 'units2': 30, 'dense_units': 100}. Best is trial 0 with value: 0.7162570973172621.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:24:00,722]\u001b[0m Trial 1 finished with value: 0.7612147339524218 and parameters: {'LSTM_dropout': 0.7000000000000001, 'dropout': 0.5, 'spatial_dropout': 0.0, 'lr': 0.0011488686702275726, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop'>, 'units1': 40, 'units2': 30, 'dense_units': 30}. Best is trial 1 with value: 0.7612147339524218.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:24:19,606]\u001b[0m Trial 2 finished with value: 0.6211113873737609 and parameters: {'LSTM_dropout': 0.1, 'dropout': 0.4, 'spatial_dropout': 0.1, 'lr': 1.4526264674440828e-05, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'units1': 10, 'units2': 10, 'dense_units': 70}. Best is trial 1 with value: 0.7612147339524218.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:24:39,353]\u001b[0m Trial 3 finished with value: 0.7373372457457773 and parameters: {'LSTM_dropout': 0.6000000000000001, 'dropout': 0.7000000000000001, 'spatial_dropout': 0.2, 'lr': 0.00018938833803018655, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop'>, 'units1': 30, 'units2': 30, 'dense_units': 20}. Best is trial 1 with value: 0.7612147339524218.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:24:58,765]\u001b[0m Trial 4 finished with value: 0.760006313205212 and parameters: {'LSTM_dropout': 0.6000000000000001, 'dropout': 0.2, 'spatial_dropout': 0.30000000000000004, 'lr': 0.00011673751998501406, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop'>, 'units1': 100, 'units2': 100, 'dense_units': 60}. Best is trial 1 with value: 0.7612147339524218.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:25:11,100]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:25:16,365]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:25:35,275]\u001b[0m Trial 7 finished with value: 0.7736231351248783 and parameters: {'LSTM_dropout': 0.0, 'dropout': 0.7000000000000001, 'spatial_dropout': 0.2, 'lr': 0.0014412607498493553, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'units1': 90, 'units2': 30, 'dense_units': 90}. Best is trial 7 with value: 0.7736231351248783.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:25:40,624]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:25:46,217]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:26:06,029]\u001b[0m Trial 10 finished with value: 0.7769143044442431 and parameters: {'LSTM_dropout': 0.4, 'dropout': 0.8, 'spatial_dropout': 0.4, 'lr': 0.0020107423055999545, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'units1': 70, 'units2': 60, 'dense_units': 90}. Best is trial 10 with value: 0.7769143044442431.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:26:25,703]\u001b[0m Trial 11 finished with value: 0.773945730222203 and parameters: {'LSTM_dropout': 0.4, 'dropout': 0.8, 'spatial_dropout': 0.4, 'lr': 0.0026098802176422937, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'units1': 70, 'units2': 60, 'dense_units': 90}. Best is trial 10 with value: 0.7769143044442431.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:26:39,073]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 8.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:26:44,509]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:27:04,134]\u001b[0m Trial 14 finished with value: 0.7647165691819338 and parameters: {'LSTM_dropout': 0.30000000000000004, 'dropout': 0.6000000000000001, 'spatial_dropout': 0.4, 'lr': 0.00044987774279512055, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'units1': 70, 'units2': 80, 'dense_units': 90}. Best is trial 10 with value: 0.7769143044442431.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:27:09,674]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:27:15,169]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:27:22,618]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 2.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:27:33,082]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:27:47,446]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:27:52,876]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:28:12,516]\u001b[0m Trial 21 finished with value: 0.7573486933091116 and parameters: {'LSTM_dropout': 0.0, 'dropout': 0.7000000000000001, 'spatial_dropout': 0.2, 'lr': 0.0019036654152229887, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'units1': 80, 'units2': 70, 'dense_units': 90}. Best is trial 10 with value: 0.7769143044442431.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:28:32,273]\u001b[0m Trial 22 finished with value: 0.7732613329878573 and parameters: {'LSTM_dropout': 0.1, 'dropout': 0.7000000000000001, 'spatial_dropout': 0.2, 'lr': 0.0029584889683722214, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'units1': 90, 'units2': 40, 'dense_units': 90}. Best is trial 10 with value: 0.7769143044442431.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:28:37,842]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:28:45,220]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 2.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:29:05,242]\u001b[0m Trial 25 finished with value: 0.7669914964366564 and parameters: {'LSTM_dropout': 0.4, 'dropout': 0.6000000000000001, 'spatial_dropout': 0.4, 'lr': 0.009647488752772599, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'units1': 60, 'units2': 50, 'dense_units': 50}. Best is trial 10 with value: 0.7769143044442431.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:29:10,650]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:29:16,017]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:29:21,394]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:29:26,967]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:29:32,415]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:29:52,159]\u001b[0m Trial 31 finished with value: 0.7571975539140081 and parameters: {'LSTM_dropout': 0.1, 'dropout': 0.7000000000000001, 'spatial_dropout': 0.2, 'lr': 0.0031079587286798704, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'units1': 90, 'units2': 40, 'dense_units': 90}. Best is trial 10 with value: 0.7769143044442431.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:30:12,126]\u001b[0m Trial 32 finished with value: 0.7739130993453218 and parameters: {'LSTM_dropout': 0.1, 'dropout': 0.6000000000000001, 'spatial_dropout': 0.30000000000000004, 'lr': 0.0011797466269459092, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'units1': 80, 'units2': 30, 'dense_units': 90}. Best is trial 10 with value: 0.7769143044442431.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:30:31,384]\u001b[0m Trial 33 finished with value: 0.7703485207585583 and parameters: {'LSTM_dropout': 0.0, 'dropout': 0.6000000000000001, 'spatial_dropout': 0.30000000000000004, 'lr': 0.0012518523642155667, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'units1': 80, 'units2': 30, 'dense_units': 80}. Best is trial 10 with value: 0.7769143044442431.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:30:45,549]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:31:06,318]\u001b[0m Trial 35 finished with value: 0.7726883537532708 and parameters: {'LSTM_dropout': 0.1, 'dropout': 0.5, 'spatial_dropout': 0.30000000000000004, 'lr': 0.009280301551054335, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'units1': 80, 'units2': 50, 'dense_units': 60}. Best is trial 10 with value: 0.7769143044442431.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:31:11,805]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:31:18,756]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-22 22:31:24,475]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:31:30,361]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:31:36,059]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:31:56,747]\u001b[0m Trial 41 finished with value: 0.7706593496953655 and parameters: {'LSTM_dropout': 0.1, 'dropout': 0.7000000000000001, 'spatial_dropout': 0.2, 'lr': 0.002890177381116407, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'units1': 90, 'units2': 40, 'dense_units': 90}. Best is trial 10 with value: 0.7769143044442431.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:32:02,213]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:32:22,990]\u001b[0m Trial 43 finished with value: 0.7732009650772109 and parameters: {'LSTM_dropout': 0.1, 'dropout': 0.7000000000000001, 'spatial_dropout': 0.30000000000000004, 'lr': 0.0040816444746307285, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'units1': 100, 'units2': 30, 'dense_units': 100}. Best is trial 10 with value: 0.7769143044442431.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:32:43,820]\u001b[0m Trial 44 finished with value: 0.7782287970426207 and parameters: {'LSTM_dropout': 0.4, 'dropout': 0.6000000000000001, 'spatial_dropout': 0.1, 'lr': 0.005733554663300928, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'units1': 70, 'units2': 50, 'dense_units': 90}. Best is trial 44 with value: 0.7782287970426207.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:33:04,626]\u001b[0m Trial 45 finished with value: 0.7696714526485419 and parameters: {'LSTM_dropout': 0.4, 'dropout': 0.4, 'spatial_dropout': 0.1, 'lr': 0.004954978006187183, 'optimizer': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, 'units1': 70, 'units2': 50, 'dense_units': 80}. Best is trial 44 with value: 0.7782287970426207.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:33:15,488]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 5.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:33:21,424]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:33:27,228]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 0.\u001b[0m\n",
      "\u001b[32m[I 2021-08-22 22:33:42,231]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63bb3bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LSTM_dropout': 0.4,\n",
       " 'dropout': 0.6000000000000001,\n",
       " 'spatial_dropout': 0.1,\n",
       " 'lr': 0.005733554663300928,\n",
       " 'optimizer': tensorflow.python.keras.optimizer_v2.adam.Adam,\n",
       " 'units1': 70,\n",
       " 'units2': 50,\n",
       " 'dense_units': 90}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "trial.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8ae90a",
   "metadata": {},
   "source": [
    "# LSTM with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed46269",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open('glove.6B/glove.6B.200d.txt','r', encoding=\"utf8\") as f:\n",
    "    for line in tqdm(f):\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 200  \n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "#initialize embedding matrix with zeros\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "\n",
    "#add glove word encodings to our library\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        \n",
    "        #words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "print(\"Our embedded matrix is of dimension\", embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe510311",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(len(word_index) + 1, EMBEDDING_DIM, weights = [embedding_matrix],\n",
    "                     input_length = 23, trainable = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5389af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m5_glove(dropout_val):\n",
    "            \n",
    "    #define inputs\n",
    "    nlp_input = Input(shape = (40,), name = 'nlp_input')\n",
    "    meta_input_train = Input(shape = (7, ), name = 'meta_train')\n",
    "    \n",
    "    emb = embedding(nlp_input)\n",
    "    emb = SpatialDropout1D(dropout_val)(emb)\n",
    "\n",
    "    nlp_out = Bidirectional(LSTM(100, \n",
    "                                 dropout=dropout_val, \n",
    "                                 ))(emb)     \n",
    "     \n",
    "    #add meta data    \n",
    "    x = Concatenate()([nlp_out, meta_input_train])\n",
    "    \n",
    "    #add second hidden layer\n",
    "#    x = Dropout(dropout_val)(x)\n",
    "#    x = (Dense(50, \n",
    "#               activation = LeakyReLU(alpha=0.01)\n",
    "#              ))(x)\n",
    "    \n",
    "    #add output layer\n",
    "    x = Dropout(dropout_val)(x)\n",
    "    preds = Dense(1, \n",
    "                  activation='sigmoid'\n",
    "                 )(x)\n",
    "    \n",
    "    #compile model\n",
    "    model = Model(inputs=[nlp_input , meta_input_train], outputs = preds)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = Adam(0.001), metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c3810",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model5 = m5_glove(0.4)\n",
    "model_process(model5, 50, '05 GloVe LSTM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e281faa4",
   "metadata": {},
   "source": [
    "# GloVe dual LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b32aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m6_glove2(dropout_val):\n",
    "            \n",
    "    #define inputs\n",
    "    nlp_input = Input(shape = (40,), name = 'nlp_input')\n",
    "    meta_input_train = Input(shape = (7, ), name = 'meta_train')\n",
    "    \n",
    "\n",
    "    emb = embedding(nlp_input)\n",
    "    emb = SpatialDropout1D(dropout_val)(emb)\n",
    "\n",
    "    \n",
    "    nlp_out = Bidirectional(LSTM(130, \n",
    "                                 dropout=dropout_val,\n",
    "                                 return_sequences=True))(emb)    \n",
    "    \n",
    "    nlp_out = SpatialDropout1D(dropout_val)(nlp_out)\n",
    "    \n",
    "    nlp_out = Bidirectional(LSTM(110, \n",
    "                                 dropout=dropout_val))(emb)    \n",
    "    \n",
    "     \n",
    "    #add meta data    \n",
    "    x = Concatenate()([nlp_out, meta_input_train])\n",
    "    \n",
    "    #add second hidden layer\n",
    "    x = Dropout(dropout_val)(x)\n",
    "    x = (Dense(90, \n",
    "               activation = 'relu'\n",
    "              ))(x)\n",
    "    \n",
    "    #add output layer\n",
    "    x = Dropout(dropout_val)(x)\n",
    "    preds = Dense(1, \n",
    "                  activation='sigmoid'\n",
    "                 )(x)\n",
    "    \n",
    "    #compile model\n",
    "    model = Model(inputs=[nlp_input , meta_input_train], outputs = preds)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = Adam(0.002), metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3d3bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model6 = m6_glove2(0.4)\n",
    "model_process(model6, 50, '06 GloVe dual lstm', '06 GloVe dual lstm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc919632",
   "metadata": {},
   "source": [
    "# model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb59657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    LSTM_dropout = trial.suggest_discrete_uniform('dropout', 0.0, 0.8, 0.1)\n",
    "    dropout = trial.suggest_discrete_uniform('dropout', 0.0, 0.8, 0.1)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = trial.suggest_categorical(\"optimizer\", [Adam, RMSprop])\n",
    "    \n",
    "    LSTM1 = trial.suggest_int('units1', 20, 200, step=10)\n",
    "    LSTM2 = trial.suggest_int('units2', 20, 200, step=10)\n",
    "    dense_units = trial.suggest_int('units3', 20, 200, step=10)\n",
    "    \n",
    "    \n",
    "    \n",
    "    nlp_input = Input(shape = (40,), name = 'nlp_input')\n",
    "    meta_input_train = Input(shape = (7, ), name = 'meta_train')\n",
    "    \n",
    "    emb = embedding(nlp_input)\n",
    "    emb = SpatialDropout1D(dropout)(emb)\n",
    "\n",
    "    nlp_out = Bidirectional(LSTM(LSTM1, \n",
    "                                 dropout=LSTM_dropout,\n",
    "                                 return_sequences=True))(emb)    \n",
    "    \n",
    "    nlp_out = SpatialDropout1D(dropout)(nlp_out)\n",
    "    \n",
    "    nlp_out = Bidirectional(LSTM(LSTM2, \n",
    "                                 dropout=LSTM_dropout))(emb)    \n",
    "    \n",
    "     \n",
    "    #add meta data    \n",
    "    x = Concatenate()([nlp_out, meta_input_train])\n",
    "    \n",
    "    #add second hidden layer\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = (Dense(dense_units, \n",
    "               activation = 'relu'\n",
    "              ))(x)\n",
    "    \n",
    "    #add output layer\n",
    "    x = Dropout(dropout)(x)\n",
    "    preds = Dense(1, \n",
    "                  activation='sigmoid'\n",
    "                 )(x)\n",
    "    \n",
    "    #compile model\n",
    "    model = Model(inputs=[nlp_input , meta_input_train], outputs = preds)\n",
    "\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = optimizer(lr), metrics = ['accuracy'])\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', \n",
    "                              factor = 0.5, \n",
    "                              verbose = False, \n",
    "                              patience = 4,                        \n",
    "                              min_lr = 0.0001)\n",
    "    \n",
    "    model.fit(x=[X_train_data, meta_train],\n",
    "                        y=y_train,\n",
    "                        epochs = 30,\n",
    "                        verbose=False,\n",
    "                        callbacks=[reduce_lr],\n",
    "                        validation_data = ([X_val_data, meta_val], y_val),\n",
    "                        shuffle=True\n",
    "                       )\n",
    "    y_pred = (model.predict([test_data, meta_test]) > 0.5).astype(int)\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fa9056",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ec52f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = study.best_trial\n",
    "trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efa92cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = study.best_trial\n",
    "trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6a7d9967",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_dual = pd.read_csv('glove single lstm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "57d5425d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7940573057197762"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7869388717154875"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7989580140974564"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7363344051446945"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, glove_dual['target'], average='weighted')\n",
    "f1_score(y_true, glove_dual['target'], average='macro')\n",
    "f1_score(y_true, glove_dual['target'], average='micro')\n",
    "f1_score(y_true, glove_dual['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "86ce34fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=glove_dual.drop(columns = ['prob'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "88bd62ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('08 glove dual lstm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb57d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
